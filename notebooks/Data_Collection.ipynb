{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAPER-TITLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieving ISMIR Papers with Code from Arxiv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all of the papers from 2011 to 2020 of ISMIR are uploaded to Arxiv, this reminds the importance of all-in-one platform for this purpose to easily collect data for such researches. Here, via web scrapping, we get the papers that are uploaded to Arxiv and retrieve the information on whether they provided their code/data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, time\n",
    "import json\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import urllib, json, re\n",
    "\n",
    "import os\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Get corresponding arxiv links for the selected papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_proceeding_json = \"selected_years/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arxiv_query(max_result=1):\n",
    "    paper_urls = {}\n",
    "    for d,r,f in os.walk(path_to_proceeding_json):\n",
    "        for file in f:\n",
    "            if file.endswith(\".json\"):\n",
    "                titles = []\n",
    "                try:\n",
    "                    with open(path_to_json+file, 'r') as output:\n",
    "                        f_out = json.load(output)\n",
    "                        for keys in f_out:\n",
    "                            \n",
    "                            #Since the paper titles may include characthers such as .,-,?\n",
    "                            #They need to be replaced with space\n",
    "                            #This query method can be improved\n",
    "                            paper_title = keys['title'].lower().replace(\" \",\"+\").replace(\".\",\"\").replace(\",\",\"\").replace(\":\",\"\").replace(\";\",\"\").replace(\"?\",\"\").replace(\"-\",\"\").replace(\"'\",\"\").replace(\"-\",\"+\")\n",
    "                            \n",
    "                            #Create the query for given paper to use Arxiv API\n",
    "                            url = 'http://export.arxiv.org/api/query?search_query=ti:{}&start=0&max_results={}'.format(paper_title, max_result)\n",
    "                            \n",
    "                            with urllib.request.urlopen(url) as ur:\n",
    "                                r = ur.read()\n",
    "                            \n",
    "                            #The links to the arxiv page are stored within this element\n",
    "                            #A basic regex search\n",
    "                            match = re.findall('<link title=\"pdf\" href=(.*)',r.decode(\"utf-8\"))\n",
    "                            for paper_url in match:\n",
    "                                paper = paper_url.split(\" \")[0].split('\"')[1]\n",
    "                                paper_urls[keys['title']] = paper.replace(\"pdf\",\"abs\")\n",
    "                except:\n",
    "                    pass\n",
    "    return paper_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paper_urls = arxiv_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to CSV for file type consistency in upcoming steps\n",
    "df = pd.DataFrame({'titles':list(paper_urls.keys()),'arxiv_links':list(paper_urls.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data\n",
    "df.to_csv(\"titles_arxiv_links.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Retrieve Links of Publicly Available Code/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"titles_arxiv_links.csv\")\n",
    "papers = df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_dict = {}\n",
    "for title, link in zip(papers['titles'].values(),papers['arxiv_links'].values()):\n",
    "    papers_dict[title] = link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_links(urls):\n",
    "    driver = webdriver.Firefox(executable_path=GeckoDriverManager().install())\n",
    "    paper_code = {}\n",
    "    for title, url in urls.items():\n",
    "        driver.get(url)\n",
    "        driver.delete_all_cookies()\n",
    "        try:\n",
    "            tit = driver.find_element_by_xpath('//h1[@class=\"title mathjax\"]')\n",
    "            d = driver.find_element_by_xpath('//div[@id=\"pwc-output\"]/p/a')\n",
    "            paper_code[title] = {}\n",
    "            paper_code[title][tit.text] = {url: None}\n",
    "            if d.get_attribute(name='href'):\n",
    "                paper_code[title][tit.text][url] = d.get_attribute(name='href')\n",
    "            else:\n",
    "                paper_code[title][tit.text][url] = None\n",
    "        except:\n",
    "            pass\n",
    "        main_page = driver.window_handles[0]\n",
    "        driver.switch_to.window(main_page)\n",
    "    return paper_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = get_code_links(papers_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dic = {}\n",
    "paper_title = []\n",
    "arxiv_title = []\n",
    "arxiv_link = []\n",
    "code_link = []\n",
    "for key, val in final_results.items():\n",
    "    paper_title.append(key)\n",
    "    for k2,v2 in val.items():\n",
    "        arxiv_title.append(k2)\n",
    "        for k3,v3 in v2.items():\n",
    "            arxiv_link.append(k3)\n",
    "            code_link.append(v3)\n",
    "csv_dic['paper_title'] = paper_title\n",
    "csv_dic['arxiv_title'] = arxiv_title\n",
    "csv_dic['arxiv_link'] = arxiv_link\n",
    "csv_dic['code_link'] = code_link\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arxiv_res = pd.DataFrame(csv_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arxiv_res.to_csv('arxiv_implementation_results.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of this approach, the papers were manually annotated such as `with code/without code`. \n",
    "\n",
    "Since not all of the papers of ISMIR are uploaded to Arxiv and the query may fail in some cases, the output file `arxiv_implementation_results.csv` is manually filtered by comparing the title of the paper and the title of the paper from Arxiv. The merged version is `ismir_2011_2021_with_implementation.csv`.\n",
    "\n",
    "For the next steps, we should have three different data: CSV with:\n",
    "\n",
    "1. Titles, year of all papers\n",
    "\n",
    "2. Titles, year of the papers with code\n",
    "\n",
    "3. Titles, year of the papers without code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_year_dic = {}\n",
    "for d,r,f in os.walk(path_to_json):\n",
    "    for file in f:\n",
    "        if file.endswith(\".json\"):\n",
    "            with open(path_to_proceeding_json+file, 'r') as output:\n",
    "                f_out = json.load(output)\n",
    "            for keys in f_out:\n",
    "                title_year_dic[keys['title']] = file.split(\".\")[0]\n",
    "df_all_papers = pd.DataFrame(title_year_dic, index=[0])\n",
    "df_all_papers = df_all_papers.T\n",
    "df_all_papers.reset_index(inplace=True)\n",
    "df_all_papers.rename(columns={'index':'titles',0:'year'},inplace=True)\n",
    "df_all_papers.to_csv(\"ismir_2011_2020_papers.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_papers.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_papers_with_code = pd.read_csv(\"ismir_2011_2020_with_implementation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_papers_without_code = df_all_papers[~df_all_papers['titles'].isin(df_papers_with_code['titles'].to_list())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_papers_without_code.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_papers_without_code.to_csv(\"ismir_2011_2020_without_implementation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. **Creating subcategories of the papers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ISMIR Papers do not have a keywords section & this leads to a problem on the categorisation of the papers. Since there isn't a common agreement on the subtopics of Music Information Retrieval, for this research, we decided to use `http://www.music.mcgill.ca/~ich/classes/mumt621_15/MIR_topics.html` as base and extended the keywords by iterating over the titles of the papers. This is not a solid solution but such a data is required for further analysis on open data/code in MIR.\n",
    "\n",
    "This subtopics are stored in JSON format: `mir_topics.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mir_topics.json', 'r') as mir_out:\n",
    "    mir_topics = json.load(mir_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise_papers(df):\n",
    "    df['category'] = None\n",
    "    for idx, row in df.iterrows():\n",
    "        row = row.copy()\n",
    "        categories = []\n",
    "        for key, val in mir_topics.items():\n",
    "            for v in val:\n",
    "                title = [t.lower() for t in row.titles.replace(\"-\",\" \").replace(\":\",\" \").split(\" \")]\n",
    "                if v.lower() in title:\n",
    "                    categories.append(key)\n",
    "        if categories == []:\n",
    "            categories = \"Other\"\n",
    "        else:\n",
    "            categories = \",\".join(cat for cat in set(categories))\n",
    "        df.loc[idx, 'category']= categories\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = categorise_papers(df_all_papers)\n",
    "df_papers_with_code_cat = categorise_papers(df_papers_with_code)\n",
    "df_papers_without_code_cat = categories(df_papers_without_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ismir_2011_2020_papers_categorized.csv\", index=None)\n",
    "df_papers_with_code_cat.to_csv(\"ismir_2011_2020_papers_with_code_categorized.csv\", index=None)\n",
    "df_papers_without_code.to_csv(\"ismir_2011_2020_papers_without_code_categorized.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finding Papers Published an Open Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an intuition, we could say that dataset/database creation among MIR community has increased but this can be analyzed by searching for the amount of published papers for dataset/database creation. To do that, our approach is to search for the titles including words such as `dataset` and `database`.\n",
    "\n",
    "The next step is to manually check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "for idx, row in df_all_papers.iterrows():\n",
    "    for single_word in row.titles.replace(\".\",\"\").split(\" \"):\n",
    "        if single_word.lower() == 'dataset':\n",
    "            dataset[row.titles] = row.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.DataFrame(dataset, index=[0])\n",
    "df_dataset = df_dataset.T\n",
    "df_dataset.reset_index(inplace=True)\n",
    "df_dataset.rename(columns={'index':'titles',0:'year'},inplace=True)\n",
    "df_dataset.to_csv(\"ismir_2011_2020_dataset.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
